{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import gspread_dataframe as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Dates of the campaign\n",
    "dates = ['2022-10-14', '2023-01-06']\n",
    "# Cluster dictionary\n",
    "cluster_names = pd.read_excel(\"/Users/gabrielreynoso/Documents/RFM_LayerA_Dic.xlsx\")\n",
    "# Create the channel dictionary\n",
    "cluster_dict = cluster_names.set_index('id').to_dict()['name']\n",
    "# BD Connection\n",
    "f = open('/Users/gabrielreynoso/Documents/Queries/db_klarprod_connection.txt', 'r')\n",
    "postgres_str = f.read()\n",
    "f.close()\n",
    "cnx = create_engine(postgres_str)\n",
    "# Read and Load Credentials\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/gabrielreynoso/Documents/GoogleCredentials/gabo_credentials.json')\n",
    "gc = gspread.authorize(credentials)\n",
    "# Export results\n",
    "writer = pd.ExcelWriter('./Results/November_ChurnCampaign_Results.xlsx', engine='xlsxwriter')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Queries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# RFM Query for data on a specific date\n",
    "query_rfm = '''\n",
    "        select rfm_layer.user_id,\n",
    "               max_user.max_date as date,\n",
    "               rfm_layer.cluster,\n",
    "               rfm_layer.time,\n",
    "               rfm_layer.monetary,\n",
    "               rfm_layer.frequency,\n",
    "               rfm_layer.recency\n",
    "        from growth.rfm_history as rfm_layer,\n",
    "             (select user_id,\n",
    "                     max(date) as max_date\n",
    "             from growth.rfm_history\n",
    "             where date < '{}'::date\n",
    "             group by user_id) max_user\n",
    "        where rfm_layer.user_id = max_user.user_id\n",
    "        and rfm_layer.date = max_user.max_date\n",
    "        and rfm_layer.user_id in {}\n",
    "'''\n",
    "# Purchases for the users in the specific date\n",
    "query_p = '''\n",
    "        select\n",
    "               t.user_id,\n",
    "               count(transaction_id) as purchases,\n",
    "                -1*sum(amount) as total_amount\n",
    "        from analytics_bi.transactions as t\n",
    "        where t.type in ('PURCHASE')\n",
    "          and t.timestamp_mx_created_at between {} and  {}\n",
    "          and t.state = 'SETTLED'\n",
    "          and t.source_account_internal_id <> '0000000000000000'\n",
    "          and t.source_account_internal_id <> '00000000-0000-0000-0000-000000000000'\n",
    "          and t.provider_id <> 'KLAR'\n",
    "          and t.user_id in {}\n",
    "        group by t.user_id\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "cohort_query = '''\n",
    "select\n",
    "    klar_user_id as user_id,\n",
    "    segment_name,\n",
    "    case when segment_name like '%MAR%' then 'More at risk'\n",
    "         when segment_name like '%More at risk%' then 'More at risk' else 'Churned' end as cohort,\n",
    "    case when segment_name like '%Trigger%' then 'Trigger'\n",
    "         when segment_name like '%Treatment' then 'Treatment' else 'Control' end as type_segment\n",
    "from is_customer_io.segments\n",
    "where segment_name like '%RFM November%'\n",
    "and type_segment != 'Trigger';\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cohort_info = pd.read_sql_query(sqlalchemy.text(cohort_query),cnx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Churn RFM November - Churn Treatment       104927\nChurn RFM November - Churn Control          69614\nChurn RFM November - MAR 0,75 Treatment     57234\nChurn RFM November - MAR 0,75 Control       38572\nChurn RFM November - MAR 75,- Treatment      8531\nChurn RFM November - MAR 75,- Control        5715\nName: segment_name, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_info.segment_name.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                user_id  \\\n0  000145c0-671b-4563-bbd0-88cb0f44f420   \n1  0001be16-8430-4314-bac4-f23119645859   \n2  0001e0b1-14de-48c6-b41f-d0ec240c6e95   \n3  0001e46b-bade-479e-967f-0481ed7318cb   \n4  00026f33-68e7-479f-83aa-36f19a2846cc   \n\n                            segment_name        cohort type_segment  \n0   Churn RFM November - Churn Treatment       Churned    Treatment  \n1  Churn RFM November - MAR 0,75 Control  More at risk      Control  \n2     Churn RFM November - Churn Control       Churned      Control  \n3  Churn RFM November - MAR 0,75 Control  More at risk      Control  \n4   Churn RFM November - Churn Treatment       Churned    Treatment  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>segment_name</th>\n      <th>cohort</th>\n      <th>type_segment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000145c0-671b-4563-bbd0-88cb0f44f420</td>\n      <td>Churn RFM November - Churn Treatment</td>\n      <td>Churned</td>\n      <td>Treatment</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0001be16-8430-4314-bac4-f23119645859</td>\n      <td>Churn RFM November - MAR 0,75 Control</td>\n      <td>More at risk</td>\n      <td>Control</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0001e0b1-14de-48c6-b41f-d0ec240c6e95</td>\n      <td>Churn RFM November - Churn Control</td>\n      <td>Churned</td>\n      <td>Control</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001e46b-bade-479e-967f-0481ed7318cb</td>\n      <td>Churn RFM November - MAR 0,75 Control</td>\n      <td>More at risk</td>\n      <td>Control</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00026f33-68e7-479f-83aa-36f19a2846cc</td>\n      <td>Churn RFM November - Churn Treatment</td>\n      <td>Churned</td>\n      <td>Treatment</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_info.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cohorts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Read a worksheet into a Dataframe\n",
    "churned = cohort_info[cohort_info.cohort=='Churned']\n",
    "more_risk_1 = cohort_info[cohort_info.segment_name.str.contains('0,75')]\n",
    "more_risk_2 = cohort_info[cohort_info.segment_name.str.contains('75,-')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Treatment    104927\nControl       69614\nName: type_segment, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churned.type_segment.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['user_id', 'segment_name', 'cohort', 'type_segment'], dtype='object')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churned.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segments EDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Treatment    8531\nControl      5715\nName: type_segment, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_risk_2.type_segment.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/lql2bh7s2797fh2q6lw2ttdh0000gn/T/ipykernel_64016/1905345101.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_treatment = overall_treatment.append(aux_result)\n",
      " 50%|█████     | 1/2 [01:32<01:32, 92.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:19<00:00, 69.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.2615749835968 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:35<00:35, 35.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/lql2bh7s2797fh2q6lw2ttdh0000gn/T/ipykernel_64016/1905345101.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_treatment = overall_treatment.append(aux_result)\n",
      "100%|██████████| 2/2 [01:23<00:00, 41.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.98099684715271 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:34<00:34, 34.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/lql2bh7s2797fh2q6lw2ttdh0000gn/T/ipykernel_64016/1905345101.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_treatment = overall_treatment.append(aux_result)\n",
      "100%|██████████| 2/2 [01:09<00:00, 34.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.77745509147644 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/b_/lql2bh7s2797fh2q6lw2ttdh0000gn/T/ipykernel_64016/1905345101.py:66: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# For loop for extracting cohort information\n",
    "cohorts = {}\n",
    "cohorts_results = {}\n",
    "cohorts_movement = {}\n",
    "segment_names = ['Churned', 'At_Risk_S1', 'At_Risk_S2']\n",
    "for idx, aux in enumerate([churned, more_risk_1 , more_risk_2]):\n",
    "    # Get cohort info\n",
    "    aux = aux[~aux.user_id.isna()][['user_id', 'type_segment']]\n",
    "    # Dataframe and results dicts\n",
    "    segments_dict = {}\n",
    "    segments_results = {}\n",
    "    segments_movement = {}\n",
    "    # Print the cohort name\n",
    "    start_time = time.time()\n",
    "    overall_treatment = pd.DataFrame()\n",
    "    i = 0\n",
    "    for segment in tqdm(aux.type_segment.unique()):\n",
    "        print(segment)\n",
    "        # Filter segment\n",
    "        aux_segment = aux[aux.type_segment == segment]\n",
    "        # Start of the campaign\n",
    "        aux_start_campaign = pd.read_sql_query(query_rfm.format(dates[0], tuple(aux_segment.user_id.to_list())), cnx)\n",
    "        aux_start_campaign = aux_start_campaign.set_index('user_id')\n",
    "        # Map cluster\n",
    "        aux_start_campaign['cluster'] = aux_start_campaign['cluster'].map(cluster_dict)\n",
    "        aux_start_campaign = aux_start_campaign.add_prefix('Pre_')\n",
    "        # End of the campaign\n",
    "        aux_end_campaign = pd.read_sql_query(query_rfm.format(dates[1], tuple(aux_segment.user_id.to_list())), cnx)\n",
    "        aux_end_campaign = aux_end_campaign.set_index('user_id')\n",
    "        # Map cluster\n",
    "        aux_end_campaign['cluster'] = aux_end_campaign['cluster'].map(cluster_dict)\n",
    "        aux_end_campaign = aux_end_campaign.add_prefix('Post_')\n",
    "        # Merge Pre and Post campaign\n",
    "        aux_result = pd.merge(aux_start_campaign, aux_end_campaign, left_index=True, right_index=True)\n",
    "        aux_result = aux_result.reset_index()\n",
    "        # Purchases\n",
    "        aux_purchases = pd.read_sql_query(query_p.format(dates[0],dates[1],tuple(aux_segment.user_id.to_list())), cnx)\n",
    "        # Add Purchases to result info\n",
    "        aux_result = pd.merge(aux_result, aux_purchases, on='user_id', how='left')\n",
    "        aux_result['movement'] = aux_result['Pre_cluster'] + '->' + aux_result['Post_cluster']\n",
    "        # Add to dict of segments cohorts\n",
    "        segments_dict[segment] = aux_result\n",
    "        segments_results[segment] = aux_result.groupby('movement')[['purchases','total_amount','Pre_monetary','Pre_frequency', 'Pre_recency','Post_monetary', 'Post_frequency', 'Post_recency']].describe()\n",
    "        segments_movement[segment] = pd.concat([aux_result.movement.value_counts(), aux_result.movement.value_counts(normalize=True).mul(100)],axis=1, keys=('counts','percentage'))\n",
    "        # If not control then append to general treatment dataframe\n",
    "        if segment != 'Control':\n",
    "            overall_treatment = overall_treatment.append(aux_result)\n",
    "        # Write the results into an excel\n",
    "        segments_results[segment].to_excel(writer, startrow=i+3, startcol=0, sheet_name=segment_names[idx])\n",
    "        segments_movement[segment].to_excel(writer, startrow=i+7+segments_results[segment].shape[0], startcol=0, sheet_name=segment_names[idx])\n",
    "        worksheet = writer.sheets[segment_names[idx]]\n",
    "        worksheet.write(i, 0, segment)\n",
    "        i = i+9+segments_results[segment].shape[0] + segments_movement[segment].shape[0]\n",
    "    print(str(time.time()-start_time) + ' seconds')\n",
    "    segments_dict['Overall_Treatment'] = overall_treatment\n",
    "    segments_results['Overall_Treatment'] = overall_treatment.groupby('movement')[['purchases','total_amount','Pre_monetary','Pre_frequency', 'Pre_recency','Post_monetary', 'Post_frequency', 'Post_recency']].describe()\n",
    "    segments_movement['Overall_Treatment'] = pd.concat([overall_treatment.movement.value_counts(), overall_treatment.movement.value_counts(normalize=True).mul(100)], axis=1, keys=('counts', 'percentage'))\n",
    "    # Print the overall results table into excel\n",
    "    segments_results['Overall_Treatment'].to_excel(writer, startrow=i+3, startcol=0, sheet_name=segment_names[idx])\n",
    "    segments_movement['Overall_Treatment'].to_excel(writer, startrow=i+7+segments_results['Overall_Treatment'].shape[0], startcol=0, sheet_name=segment_names[idx])\n",
    "    worksheet = writer.sheets[segment_names[idx]]\n",
    "    worksheet.write(i, 0, 'Overall_Treatment')\n",
    "    # Add the segment dict to the cohorts dict\n",
    "    cohorts[segment_names[idx]] = segments_dict\n",
    "    cohorts_results[segment_names[idx]] = segments_results\n",
    "writer.save()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
